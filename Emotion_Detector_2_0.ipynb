{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axis121/AMLS_Project/blob/main/Emotion_Detector_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iztaEUNzOAMP",
        "outputId": "7e0d6e65-b285-4044-b2c8-fa0ae9309738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Jj4HHUOB_X"
      },
      "outputs": [],
      "source": [
        "#https://towardsdatascience.com/basic-smile-detection-using-opencv-and-dlib-aeb22afb9e67\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FKhxLRjkSjzr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "#https://stackoverflow.com/questions/3426108/how-to-sort-a-list-of-strings-numerically\n",
        "from natsort import natsorted # pip install natsort\n",
        "import os\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "09_mBJgWSqXT"
      },
      "outputs": [],
      "source": [
        "def faceLandmarks(im):\n",
        "\n",
        "    # Path for the detection model, you can download it from here: https://github.com/italojs/facial-landmarks-recognition/blob/master/shape_predictor_68_face_landmarks.dat\n",
        "    PREDICTOR_PATH = r\"/content/drive/MyDrive/Colab Notebooks/Test_folder/shape_predictor_68_face_landmarks.dat\"\n",
        "    \n",
        "    # Create object to detect the face\n",
        "    faceDetector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    # Create object to detect the facial landmarks\n",
        "    landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)\n",
        "\n",
        "    # Detect faces\n",
        "    faceRects = faceDetector(im, 0)\n",
        "\n",
        "    # Initialize landmarksAll array\n",
        "    landmarksAll = []\n",
        "\n",
        "    # For each face detected in the image, this chunk of code creates a ROI around the face and pass it as an argument to the \n",
        "    # facial landmark detector and append the result to the array landmarks \n",
        "    for i in range(0, len(faceRects)):\n",
        "        newRect = dlib.rectangle(int(faceRects[i].left()),\n",
        "                            int(faceRects[i].top()),\n",
        "                            int(faceRects[i].right()),\n",
        "                            int(faceRects[i].bottom()))\n",
        "        landmarks = landmarkDetector(im, newRect)\n",
        "        landmarksAll.append(landmarks)\n",
        "\n",
        "    return landmarksAll, faceRects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j71iWF-vSxO1"
      },
      "outputs": [],
      "source": [
        "def renderFacialLandmarks(im, landmarks):\n",
        "    \n",
        "    # Convert landmarks into iteratable array\n",
        "    points = []\n",
        "    [points.append((p.x, p.y)) for p in landmarks.parts()]\n",
        "\n",
        "    # Loop through array and draw a circle for each landmark\n",
        "    for p in points:\n",
        "        cv2.circle(im, (int(p[0]),int(p[1])), 2, (255,0,0),-1)\n",
        "\n",
        "    # Return image with facial landmarks \n",
        "    return im"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY4fvRBxHB5n"
      },
      "source": [
        "Extractions of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BstHIzNgBSnF"
      },
      "outputs": [],
      "source": [
        "def extractFeatures(folder_dir): \n",
        "    number_of_features = 136 #68 coordinates, x and y points\n",
        "    features = np.ones((1,number_of_features))*10\n",
        "    current_features = np.zeros((1,number_of_features))\n",
        "\n",
        "    for images in natsorted(os.listdir(folder_dir)):\n",
        "    \n",
        "        # check if the image ends with png\n",
        "        if (images.endswith(\".jpg\")):\n",
        "            \n",
        "            print(images) # for testing\n",
        "            #type(images)\n",
        "            ##use images to finish the directory call for im\n",
        "            ## Read an image to a variable\n",
        "            im = cv2.imread(folder_dir +\"/\" + images)\n",
        "            \n",
        "            # Get landmarks using the function created above\n",
        "            landmarks, _ = faceLandmarks(im)\n",
        "\n",
        "            if len(landmarks) == 0: #set features to 0\n",
        "                for j in range(68):\n",
        "                  current_features [0,j]=0\n",
        "                  current_features [0,j+68]=0\n",
        "\n",
        "            else:\n",
        "                # Render the landmarks on the first face detected. You can specify the face by passing the desired index to the landmarks array.\n",
        "                # In this case, one face was detected, so I'm passing landmarks[0] as the argument.\n",
        "                faceWithLandmarks = renderFacialLandmarks(im, landmarks[0])\n",
        "                for j in range(68):\n",
        "                  #print(j)\n",
        "                  current_features [0,j]=landmarks[0].parts()[0].x-landmarks[0].parts()[j].x\n",
        "                  current_features [0,j+68]=landmarks[0].parts()[0].y-landmarks[0].parts()[j].y\n",
        "        features = np.vstack((features,current_features))\n",
        "    \n",
        "    features = np.delete(features,0,axis = 0)\n",
        "    return features\n",
        "    print(\"done\")\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getSelectedFacialFeatures(features): # derive the specific features from the landmark coordinates\n",
        "  rows, cols = features.shape\n",
        "  number_of_features = 18\n",
        "  x = features [:,:68] # extract x coordinates from features matrix\n",
        "  y = features [:,-68:] # extract y coordinates from features matrix\n",
        "\n",
        "  selected_features = np.zeros((rows,number_of_features))\n",
        "\n",
        "  # lip width\n",
        "  selected_features [:,0] = x[:,48] - x[:,54]\n",
        "\n",
        "  # jaw width\n",
        "  selected_features [:,1] = x[:,2] - x[:,14]\n",
        "\n",
        "  # ratio of lip and jaw width\n",
        "  selected_features [:,2] = selected_features [:,0]/selected_features [:,1]\n",
        "\n",
        "  # MAR (Mouth Aspect Ratio) (a1 + a2)/(2*a3)\n",
        "  a1 = y[:,50] - y[:,58]\n",
        "  a2 = y[:,51] - y[:,57]\n",
        "  a3 = y[:,52] - y[:,56]\n",
        "  a4 = x[:,48] - x[:,54]\n",
        "\n",
        "  selected_features [:,3] = (a1+a2+a3)/(3*a4) \n",
        "\n",
        "  # Cheek puffiness\n",
        "  selected_features [:,4] = y[:,11] - y[:,30]\n",
        "\n",
        "  # lip curvature ## check formula\n",
        "  selected_features [:,5] = y[:,60] - y[:,66]\n",
        "\n",
        "  # Mouth corners\n",
        "  selected_features [:,6] = x[:,48]\n",
        "  selected_features [:,7] = y[:,48]\n",
        "\n",
        "  selected_features [:,8] = x[:,54]\n",
        "  selected_features [:,9] = y[:,54]\n",
        "\n",
        "  # eye corners\n",
        "\n",
        "  selected_features [:,10] = x[:,16]\n",
        "  selected_features [:,11] = y[:,16]\n",
        "\n",
        "  selected_features [:,12] = x[:,20]\n",
        "  selected_features [:,13] = y[:,20]\n",
        "\n",
        "  selected_features [:,14] = x[:,21]\n",
        "  selected_features [:,15] = y[:,21]\n",
        "\n",
        "  selected_features [:,16] = x[:,25]\n",
        "  selected_features [:,17] = y[:,25]\n",
        "\n",
        "  return abs(selected_features)"
      ],
      "metadata": {
        "id": "pbluSnY9xcJM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLabel(label_dir,column):\n",
        "  df = pd.read_csv(label_dir)\n",
        "  #df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Test_folder/dataset/labels_modified.csv')\n",
        "  #df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/Datasets/celeba/labels_modified.csv')\n",
        "  #print(df.iloc[:,3].values)\n",
        "\n",
        "\n",
        "  # replace() syntax\n",
        "  df = df.replace(-1,0)\n",
        "  labels = df.iloc[:,column].values #face shape is the 3rd coloumn, eye colour is the 2nd\n",
        "  labels = np.transpose(labels)\n",
        "\n",
        "  return labels"
      ],
      "metadata": {
        "id": "R6TIiR_Vh-MQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeMissingValues (features, labels):\n",
        "\n",
        "  rows, cols = features.shape\n",
        "  featuresAndLabels = np.column_stack((features,labels)) # combine the features and labels into one matrix, horizontally\n",
        "  featuresAndLabels = featuresAndLabels[~np.all(featuresAndLabels[:,:136] == 0, axis=1)] #remove rows if the feature row section is full of zeroes\n",
        "  featuresAndLabels = featuresAndLabels[~np.any(np.isnan(featuresAndLabels[:,:136])==True, axis=1)] #remove rows if the feature row section is full of zeroes\n",
        "  featuresAndLabels = featuresAndLabels[~np.any(np.isinf(featuresAndLabels[:,:136])==True, axis=1)] #remove rows if the feature row section is full of zeroes\n",
        "\n",
        "\n",
        "  clean_features = featuresAndLabels [:,:cols] # remake feature matrix\n",
        "  clean_labels = featuresAndLabels [:,-1] # remake label vector\n",
        "\n",
        "  return clean_features, clean_labels"
      ],
      "metadata": {
        "id": "IDI3QBB9v1g5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_dir = \"/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/Datasets/celeba/img\" # training set\n",
        "#folder_dir = \"//content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/dataset_AMLS_22-23_test/celeba_test/img\" # test set\n",
        "\n",
        "features = extractFeatures(folder_dir)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/A1/CelebA_feature_set.npy\",features)"
      ],
      "metadata": {
        "id": "BefDETqNL8Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading saved features and importing labels"
      ],
      "metadata": {
        "id": "n3o8gFMsrTZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.load(\"/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/A1/CelebA_feature_set.npy\")"
      ],
      "metadata": {
        "id": "KKN4x4JM7pHL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jqS_bYQpOhp5"
      },
      "outputs": [],
      "source": [
        "label_dir = '/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/Datasets/celeba/labels_modified.csv' # training set labels\n",
        "#label_dir = '/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/dataset_AMLS_22-23_test/cartoon_set_test/modified_labels.csv' # test set labels\n",
        "\n",
        "labels = getLabel(label_dir,column = 3) # get label vector #gender is the 3rd column, smile is the 4th"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "Hjv6YRt113V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ade32b8-a027-48b9-f912-1b279211b92c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing Data"
      ],
      "metadata": {
        "id": "bVEG49vu4ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get selected facial features\n",
        "selected_features = getSelectedFacialFeatures (features)\n",
        "#remove rows with missing values\n",
        "clean_features, clean_labels = removeMissingValues (selected_features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcOt3to24t0y",
        "outputId": "afa5ac77-7f0e-4493-ff8a-cc12a9a3e5bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a7736995b600>:16: RuntimeWarning: invalid value encountered in true_divide\n",
            "  selected_features [:,2] = selected_features [:,0]/selected_features [:,1]\n",
            "<ipython-input-6-a7736995b600>:24: RuntimeWarning: invalid value encountered in true_divide\n",
            "  selected_features [:,3] = (a1+a2+a3)/(3*a4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_features.shape)\n",
        "print(clean_labels.shape)"
      ],
      "metadata": {
        "id": "VKWamJ9Rr-9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394c41c1-20cc-432d-8bc8-04ee42598a9f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4868, 18)\n",
            "(4868,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruUCXMTdjNmz"
      },
      "source": [
        "Graph features and lables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mYjtdKJjjPzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ab574595-de31-4e7f-bf36-b27b6203e6d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "col = np.where(clean_labels>0,'b','r')\n",
        "\n",
        "feature_norm = clean_features / clean_features.max(axis=0)\n",
        "\n",
        "plt.scatter(clean_features[:,4], clean_features[:,1], c=col, s=5, linewidth=0)\n",
        "plt.xlabel(\"Feature 4\")\n",
        "plt.ylabel(\"Feature 16\")\n",
        "plt.show()\n",
        "# 1,6\n",
        "# 0 1\n",
        "# 15 0\n",
        "# 12 6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of labels\n",
        "unique, counts = np.unique(clean_labels, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSK0M-gxvG5I",
        "outputId": "9af2dc76-8bd3-4f30-ccd5-fa0497fda151"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.000e+00 2.389e+03]\n",
            " [1.000e+00 2.479e+03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain training and validation sets from feature selected dataset"
      ],
      "metadata": {
        "id": "7gPaSgIfxF1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# train test split is used to produce train and validate sets\n",
        "X_train, X_validate, Y_train, Y_validate = train_test_split(clean_features, clean_labels, test_size=0.3,random_state=109) # 70% training and 30% test"
      ],
      "metadata": {
        "id": "FryRZkg2Jf62"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain test set from separate directory of images"
      ],
      "metadata": {
        "id": "JMVubyoM1i44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##make a check to see if load file exists then reload, if it does not exist then extract."
      ],
      "metadata": {
        "id": "hoFyhO_F2rmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extract Features\n",
        "folder_dir = \"/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/dataset_AMLS_22-23_test/celeba_test/img\" # test set\n",
        "features = extractFeatures(folder_dir)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/A1/celebA_feature_test_set.npy\",features) # saving features to a file"
      ],
      "metadata": {
        "id": "Rr4nZ5K71qbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## reload features from saved file and get labels\n",
        "features_test = np.load(\"/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/A1/celebA_feature_test_set.npy\")\n",
        "\n",
        "## labels\n",
        "label_dir = '/content/drive/MyDrive/Colab Notebooks/Test_folder/Upload/dataset_AMLS_22-23_test/celeba_test/labels_modified.csv' # test set labels\n",
        "labels_test = getLabel(label_dir, column = 3) # get label vector #face shape is the 3rd column, eye colour is the 2nd\n",
        "\n",
        "# get selected facial features\n",
        "selected_features_test = getSelectedFacialFeatures (features_test)\n",
        "#remove rows with missing values\n",
        "clean_features_test, clean_labels_test = removeMissingValues (selected_features_test, labels_test)\n",
        "\n",
        "## Match naming convention\n",
        "X_test = clean_features_test\n",
        "Y_test = clean_labels_test"
      ],
      "metadata": {
        "id": "eauVOGrR2R9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a895012-1ea0-4701-9efd-321a1a271a3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a7736995b600>:16: RuntimeWarning: invalid value encountered in true_divide\n",
            "  selected_features [:,2] = selected_features [:,0]/selected_features [:,1]\n",
            "<ipython-input-6-a7736995b600>:24: RuntimeWarning: invalid value encountered in true_divide\n",
            "  selected_features [:,3] = (a1+a2+a3)/(3*a4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT2BL77-CSNh",
        "outputId": "aa1ca5a2-3cf8-4926-d849-4464f11b6976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 136)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process Test Data"
      ],
      "metadata": {
        "id": "qKhkXyEB4cbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## get selected features\n",
        "\n",
        "## remove missing values\n",
        "clean_features_test, clean_labels_test = removeMissingValues (features_test, labels_test)\n",
        "\n",
        "## Match naming convention\n",
        "X_test = clean_features_test\n",
        "Y_test = clean_labels_test"
      ],
      "metadata": {
        "id": "SyGWDKsz4cHr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVdJrA76CH8A",
        "outputId": "5f241234-67f4-48a7-ebb1-7d4ee97dfc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1979, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Validation of models"
      ],
      "metadata": {
        "id": "vgqhQnlVxux7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features required to be normalised to allow convegrence when fitting model\n",
        "X_validate_normalised = X_validate / X_validate.max(axis=0)\n",
        "X_train_normalised = X_train / X_train.max(axis=0)\n",
        "X_test_normalised = X_test / X_test.max(axis=0)"
      ],
      "metadata": {
        "id": "gJQDS8WqrxKD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tune hyperparameter for log\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
        "      'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
        "      \"penalty\": [\"l2\"],\n",
        "  \t  \"max_iter\": [100, 200, 300, 400, 500, 600, 700, 800]\n",
        "      }\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, verbose = 3)\n",
        "\n",
        "# fitting the model for grid search\n",
        "#grid.fit(X_validate, Y_validate)\n",
        "grid.fit(X_validate_normalised, Y_validate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mw2sDD2ncYL",
        "outputId": "0aa313fd-3cd0-4d61-ada1-836dc1505c85"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=800, penalty=l2, solver=newton-cg;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=800, penalty=l2, solver=newton-cg;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=800, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=800, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=800, penalty=l2, solver=newton-cg;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=800, penalty=l2, solver=lbfgs;, score=0.860 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=800, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=800, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=800, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=800, penalty=l2, solver=lbfgs;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=800, penalty=l2, solver=liblinear;, score=0.857 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=800, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=800, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=800, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=800, penalty=l2, solver=liblinear;, score=0.832 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=200, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=200, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=200, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=200, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=200, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=300, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=300, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=300, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=300, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=300, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=400, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=400, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=400, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=400, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=400, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=600, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=600, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=600, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=600, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=600, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=700, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=700, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=700, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=700, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=700, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.914 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.849 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=800, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=800, penalty=l2, solver=liblinear;, score=0.860 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=800, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=800, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=800, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=100, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=200, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=300, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=300, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=300, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=300, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=300, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=300, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=300, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=400, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=500, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=600, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=700, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=700, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=700, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=700, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=700, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=700, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=700, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=800, penalty=l2, solver=newton-cg;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=800, penalty=l2, solver=lbfgs;, score=0.870 total time=   0.0s\n",
            "[CV 1/5] END C=1, max_iter=800, penalty=l2, solver=liblinear;, score=0.887 total time=   0.0s\n",
            "[CV 2/5] END C=1, max_iter=800, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=1, max_iter=800, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=1, max_iter=800, penalty=l2, solver=liblinear;, score=0.911 total time=   0.0s\n",
            "[CV 5/5] END C=1, max_iter=800, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=0.894 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=0.887 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=100, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=200, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=200, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=200, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=200, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=200, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=300, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=300, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=300, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=300, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=300, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=300, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=300, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=300, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 4/5] END C=10, max_iter=300, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=300, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=300, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=300, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=300, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=300, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=300, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=400, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=400, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=400, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=400, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=400, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=400, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=400, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=400, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=400, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=400, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=400, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=400, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=400, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=400, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=400, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=500, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=500, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=500, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=500, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=500, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=600, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=600, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=600, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=600, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=600, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=600, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=10, max_iter=600, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=600, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=600, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=600, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=600, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=600, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=600, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=600, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=600, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=700, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=700, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=700, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=700, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=700, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=700, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=700, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=700, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=700, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=700, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=700, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=700, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=700, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=700, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=700, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=800, penalty=l2, solver=newton-cg;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=800, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=800, penalty=l2, solver=lbfgs;, score=0.884 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=800, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=800, penalty=l2, solver=lbfgs;, score=0.904 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=800, penalty=l2, solver=lbfgs;, score=0.856 total time=   0.0s\n",
            "[CV 1/5] END C=10, max_iter=800, penalty=l2, solver=liblinear;, score=0.891 total time=   0.0s\n",
            "[CV 2/5] END C=10, max_iter=800, penalty=l2, solver=liblinear;, score=0.873 total time=   0.0s\n",
            "[CV 3/5] END C=10, max_iter=800, penalty=l2, solver=liblinear;, score=0.894 total time=   0.0s\n",
            "[CV 4/5] END C=10, max_iter=800, penalty=l2, solver=liblinear;, score=0.908 total time=   0.0s\n",
            "[CV 5/5] END C=10, max_iter=800, penalty=l2, solver=liblinear;, score=0.846 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=100, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=200, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=200, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=200, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=200, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=200, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=100, max_iter=300, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=300, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=300, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=300, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=300, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=300, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=300, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n",
            "[CV 3/5] END C=100, max_iter=300, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=300, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=300, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=300, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=300, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=300, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=300, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=300, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=400, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=400, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=400, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=400, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=400, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=400, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=400, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n",
            "[CV 3/5] END C=100, max_iter=400, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=400, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=400, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=400, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=400, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=400, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=400, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=400, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n",
            "[CV 3/5] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=500, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=500, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=500, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=500, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=500, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=600, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=600, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=600, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=600, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=600, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=600, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=600, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n",
            "[CV 3/5] END C=100, max_iter=600, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=600, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=600, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=600, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=600, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=600, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=600, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=600, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=700, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=700, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=700, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=700, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=700, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=700, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=700, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n",
            "[CV 3/5] END C=100, max_iter=700, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=700, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=700, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=700, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=700, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=700, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=700, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=700, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=800, penalty=l2, solver=newton-cg;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=100, max_iter=800, penalty=l2, solver=lbfgs;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=100, max_iter=800, penalty=l2, solver=lbfgs;, score=0.880 total time=   0.1s\n",
            "[CV 3/5] END C=100, max_iter=800, penalty=l2, solver=lbfgs;, score=0.901 total time=   0.1s\n",
            "[CV 4/5] END C=100, max_iter=800, penalty=l2, solver=lbfgs;, score=0.897 total time=   0.1s\n",
            "[CV 5/5] END C=100, max_iter=800, penalty=l2, solver=lbfgs;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END C=100, max_iter=800, penalty=l2, solver=liblinear;, score=0.898 total time=   0.0s\n",
            "[CV 2/5] END C=100, max_iter=800, penalty=l2, solver=liblinear;, score=0.880 total time=   0.0s\n",
            "[CV 3/5] END C=100, max_iter=800, penalty=l2, solver=liblinear;, score=0.901 total time=   0.0s\n",
            "[CV 4/5] END C=100, max_iter=800, penalty=l2, solver=liblinear;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END C=100, max_iter=800, penalty=l2, solver=liblinear;, score=0.853 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=LogisticRegression(),\n",
              "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
              "                         'max_iter': [100, 200, 300, 400, 500, 600, 700, 800],\n",
              "                         'penalty': ['l2'],\n",
              "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af95Vl_wpF36",
        "outputId": "505262f7-92ec-40ab-9132-fe56e307e70a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "LogisticRegression(C=1, solver='newton-cg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ideal parameters\n",
        "#{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "\n",
        "#logistic regression model\n",
        "logr_model = LogisticRegression(C = 1, max_iter = 100, penalty = \"l2\", solver = \"newton-cg\")\n",
        "logr_model.fit(X_train_normalised, Y_train)\n",
        "\n",
        "preds = logr_model.predict(X_test_normalised)\n",
        "print(metrics.classification_report(preds, Y_test))\n",
        "metrics.confusion_matrix(Y_test,preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwukLWbpJX16",
        "outputId": "55dfbe50-bdef-4277-faeb-aff480dbd257"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.88      0.90       500\n",
            "         1.0       0.88      0.92      0.90       477\n",
            "\n",
            "    accuracy                           0.90       977\n",
            "   macro avg       0.90      0.90      0.90       977\n",
            "weighted avg       0.90      0.90      0.90       977\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[442,  36],\n",
              "       [ 58, 441]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tuning hyper parameters of svm rbf model using validation set\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm\n",
        "\n",
        "# normalise validation features data\n",
        "#X_test_normalised = X_validate / X_validate.max(axis=0)\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "\t\t\t'kernel': ['linear']}\n",
        "\n",
        "grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_validate, Y_validate)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIlmA8HFL09n",
        "outputId": "9ab833d4-2858-48a5-87e1-0254943d6d1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.908 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.901 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.870 total time=   0.1s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.908 total time=   0.1s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.901 total time=   0.1s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.870 total time=   0.1s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.908 total time=   0.0s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.901 total time=   0.1s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.870 total time=   0.1s\n",
            "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.908 total time=   0.0s\n",
            "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.901 total time=   0.0s\n",
            "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.853 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.898 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.908 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.901 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.853 total time=   0.1s\n",
            "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.856 total time=   0.3s\n",
            "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.908 total time=   0.3s\n",
            "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.846 total time=   0.3s\n",
            "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.856 total time=   0.3s\n",
            "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.908 total time=   0.2s\n",
            "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.846 total time=   0.3s\n",
            "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.904 total time=   0.3s\n",
            "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.856 total time=   0.3s\n",
            "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.908 total time=   0.2s\n",
            "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.846 total time=   0.3s\n",
            "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.904 total time=   0.3s\n",
            "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.856 total time=   0.3s\n",
            "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.908 total time=   0.2s\n",
            "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.846 total time=   0.3s\n",
            "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.904 total time=   0.3s\n",
            "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.856 total time=   0.3s\n",
            "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.908 total time=   0.2s\n",
            "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.904 total time=   0.4s\n",
            "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.846 total time=   0.3s\n",
            "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.911 total time=   4.7s\n",
            "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.856 total time=   2.8s\n",
            "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.908 total time=   3.0s\n",
            "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.908 total time=   3.6s\n",
            "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.849 total time=   3.2s\n",
            "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.911 total time=   4.7s\n",
            "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.856 total time=   2.8s\n",
            "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.908 total time=   3.9s\n",
            "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.908 total time=   5.3s\n",
            "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.849 total time=   3.2s\n",
            "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.911 total time=   4.7s\n",
            "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.856 total time=   2.7s\n",
            "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.908 total time=   4.4s\n",
            "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.908 total time=   3.5s\n",
            "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.849 total time=   3.1s\n",
            "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.911 total time=   4.7s\n",
            "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.856 total time=   2.8s\n",
            "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.908 total time=   3.0s\n",
            "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.908 total time=   3.6s\n",
            "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.849 total time=   3.1s\n",
            "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.911 total time=   4.7s\n",
            "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.856 total time=   2.8s\n",
            "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.908 total time=   3.0s\n",
            "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.908 total time=   3.6s\n",
            "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.849 total time=   3.1s\n",
            "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.901 total time=  11.8s\n",
            "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.853 total time=  14.5s\n",
            "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.901 total time=  11.8s\n",
            "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.901 total time=  13.5s\n",
            "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.846 total time=  17.9s\n",
            "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.901 total time=  11.8s\n",
            "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.853 total time=  14.6s\n",
            "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.901 total time=  11.8s\n",
            "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.901 total time=  13.4s\n",
            "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.846 total time=  17.9s\n",
            "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.901 total time=  12.9s\n",
            "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.853 total time=  14.5s\n",
            "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.901 total time=  11.7s\n",
            "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.901 total time=  13.4s\n",
            "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.846 total time=  17.9s\n",
            "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.901 total time=  11.7s\n",
            "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.853 total time=  14.5s\n",
            "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.901 total time=  11.7s\n",
            "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.901 total time=  13.5s\n",
            "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.846 total time=  17.9s\n",
            "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.901 total time=  11.7s\n",
            "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.853 total time=  14.5s\n",
            "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.901 total time=  11.7s\n",
            "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.901 total time=  13.4s\n",
            "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.846 total time=  17.9s\n",
            "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.881 total time=  25.7s\n",
            "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.856 total time=  21.3s\n",
            "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.918 total time=  29.0s\n",
            "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.890 total time=  28.8s\n",
            "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.832 total time=  27.5s\n",
            "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.881 total time=  24.4s\n",
            "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.856 total time=  21.9s\n",
            "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.918 total time=  37.7s\n",
            "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.890 total time=  32.5s\n",
            "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.832 total time=  33.4s\n",
            "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.881 total time=  27.9s\n",
            "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.856 total time=  23.4s\n",
            "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.918 total time=  32.0s\n",
            "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.890 total time=  29.5s\n",
            "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.832 total time=  28.7s\n",
            "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.881 total time=  24.6s\n",
            "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.856 total time=  23.2s\n",
            "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.918 total time=  29.0s\n",
            "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.890 total time=  29.3s\n",
            "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.832 total time=  27.7s\n",
            "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.881 total time=  24.5s\n",
            "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.856 total time=  21.4s\n",
            "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.918 total time=  30.1s\n",
            "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.890 total time=  28.7s\n",
            "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.832 total time=  27.5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['linear']},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN6Bc1jRMcVJ",
        "outputId": "9c20c084-49b8-4789-bff8-70e250e28bb7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
            "SVC(C=10, gamma=1, kernel='linear')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Validation\n",
        "grid_predictions = grid.predict(X_test)\n",
        "\n",
        "# print classification report\n",
        "print(metrics.classification_report(Y_test, grid_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwRntfUJMdIN",
        "outputId": "68541a12-d741-48af-9f23-3462a86351db"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.91      0.90       478\n",
            "         1.0       0.92      0.89      0.90       499\n",
            "\n",
            "    accuracy                           0.90       977\n",
            "   macro avg       0.90      0.90      0.90       977\n",
            "weighted avg       0.90      0.90      0.90       977\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## grid searched parameters:\n",
        "# C = 10, gamma = 1, kernel = linear \n",
        "\n",
        "## training tuned model based on training set\n",
        "## features are max normalised\n",
        "from sklearn import svm\n",
        "#feaature should be normalised first\n",
        "X_validate_normalised = X_validate / X_validate.max(axis=0)\n",
        "X_train_normalised = X_train / X_train.max(axis=0)\n",
        "\n",
        "#Create a svm Classifier\n",
        "rbf_svm_model = svm.SVC(decision_function_shape='ovo',kernel='linear',C=10, gamma=1) #\n",
        "\n",
        "#Train the model using the training sets\n",
        "rbf_svm_model.fit(X_train, Y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = rbf_svm_model.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_pred, Y_test))\n",
        "metrics.confusion_matrix(Y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su-Ra8V8J3lG",
        "outputId": "72981f92-b8bf-4671-82fe-df010506dc86"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.89      0.90       488\n",
            "         1.0       0.90      0.91      0.90       489\n",
            "\n",
            "    accuracy                           0.90       977\n",
            "   macro avg       0.90      0.90      0.90       977\n",
            "weighted avg       0.90      0.90      0.90       977\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[436,  42],\n",
              "       [ 52, 447]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred = rbf_svm_model.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_pred, Y_test))\n",
        "metrics.confusion_matrix(Y_test,y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkh-nPl48ADX",
        "outputId": "7fc716cd-8ece-479a-8256-551bad4da03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         0\n",
            "         1.0       0.05      0.19      0.08       107\n",
            "         2.0       0.94      0.20      0.34      1869\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.20      1979\n",
            "   macro avg       0.20      0.08      0.08      1979\n",
            "weighted avg       0.89      0.20      0.32      1979\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,  22, 374,   0,   2],\n",
              "       [  0,  20, 377,   0,   0],\n",
              "       [  0,  25, 382,   0,   0],\n",
              "       [  0,  16, 380,   0,   1],\n",
              "       [  0,  24, 356,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/"
      ],
      "metadata": {
        "id": "cDZSkFDeb3kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model to be reloaded later"
      ],
      "metadata": {
        "id": "eLFe9XljwGHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "xQg7nZfBwF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "filename = 'A1_logr_model.sav'\n",
        "pickle.dump(logr_model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "8MS2zXLlwMmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from disk\n",
        "filename = 'A1_logr_model.sav'\n",
        "loaded_model = pickle.load(open(filename, 'rb'))"
      ],
      "metadata": {
        "id": "MNHTlRYSwM59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test loaded model\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sTXH_2Du7EqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examination of Learning Curve"
      ],
      "metadata": {
        "id": "Il5dfFllb4Qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "estimator = svm.SVC(decision_function_shape='ovo',kernel='rbf',C=100, gamma=0.0001)\n",
        "\n",
        "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, selected_features, clean_labels, cv = 5, return_times=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "g2BJk3zM1Wc4",
        "outputId": "9c80c296-8eba-455b-a142-d19d05b7d2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e7feaff1037a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#train_sizes = [1, 100, 500, 2000, 5000, 7654]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1551\u001b[0m                 \u001b[0mtrain_test_proportions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m         results = parallel(\n\u001b[0m\u001b[1;32m   1554\u001b[0m             delayed(_fit_and_score)(\n\u001b[1;32m   1555\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_score\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0msvm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLIBSVM_IMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         return libsvm.predict(\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plotting learning curve\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes,np.mean(train_scores,axis=1))\n",
        "plt.plot(train_sizes,np.mean(test_scores,axis=1))\n",
        "plt.ylabel('MSE', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for an SVM', fontsize = 18, y = 1.03)\n",
        "plt.legend([\"Train Score\", \"Test Score\"])\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI8-RVKG8dpy",
        "outputId": "b1d59d9e-44bc-4871-85f1-de8a914f3abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Glr7wF5iGn",
        "outputId": "a062e28c-44e6-4b71-dd49-a6dc23b9ff9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 638 2075 3512 4949 6387]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa4N06cJGr8G7XLwoA9Dxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}